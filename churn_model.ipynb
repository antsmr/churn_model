{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jason Hortsch 6006 Churn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Load the data set into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0    KS             128        415  382-4657         no        yes   \n",
       "1    OH             107        415  371-7191         no        yes   \n",
       "2    NJ             137        415  358-1921         no         no   \n",
       "3    OH              84        408  375-9999        yes         no   \n",
       "4    OK              75        415  330-6626        yes         no   \n",
       "\n",
       "   VMail Message  Day Mins  Day Calls  Day Charge   ...    Eve Calls  \\\n",
       "0             25     265.1        110       45.07   ...           99   \n",
       "1             26     161.6        123       27.47   ...          103   \n",
       "2              0     243.4        114       41.38   ...          110   \n",
       "3              0     299.4         71       50.90   ...           88   \n",
       "4              0     166.7        113       28.34   ...          122   \n",
       "\n",
       "   Eve Charge  Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  \\\n",
       "0       16.78       244.7           91         11.01       10.0           3   \n",
       "1       16.62       254.4          103         11.45       13.7           3   \n",
       "2       10.30       162.6          104          7.32       12.2           5   \n",
       "3        5.26       196.9           89          8.86        6.6           7   \n",
       "4       12.61       186.9          121          8.41       10.1           3   \n",
       "\n",
       "   Intl Charge  CustServ Calls  Churn?  \n",
       "0         2.70               1  False.  \n",
       "1         3.70               1  False.  \n",
       "2         3.29               0  False.  \n",
       "3         1.78               2  False.  \n",
       "4         2.73               3  False.  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that the area code 415 is listed for many states. We can also see that the churn column looks to be a string, or at the very least it is not a boolean or 0/1 representation. We can also look at all of the columns' data types just to get a better idea of what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      "State             3333 non-null object\n",
      "Account Length    3333 non-null int64\n",
      "Area Code         3333 non-null int64\n",
      "Phone             3333 non-null object\n",
      "Int'l Plan        3333 non-null object\n",
      "VMail Plan        3333 non-null object\n",
      "VMail Message     3333 non-null int64\n",
      "Day Mins          3333 non-null float64\n",
      "Day Calls         3333 non-null int64\n",
      "Day Charge        3333 non-null float64\n",
      "Eve Mins          3333 non-null float64\n",
      "Eve Calls         3333 non-null int64\n",
      "Eve Charge        3333 non-null float64\n",
      "Night Mins        3333 non-null float64\n",
      "Night Calls       3333 non-null int64\n",
      "Night Charge      3333 non-null float64\n",
      "Intl Mins         3333 non-null float64\n",
      "Intl Calls        3333 non-null int64\n",
      "Intl Charge       3333 non-null float64\n",
      "CustServ Calls    3333 non-null int64\n",
      "Churn?            3333 non-null object\n",
      "dtypes: float64(8), int64(8), object(5)\n",
      "memory usage: 572.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All of the 'object' type columns will have to be dealt with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Investigate the number of customers in each state visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAG4CAYAAAB8cQuGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4kYTYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16a89b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.plt.figure(figsize=(16,7))\n",
    "sns.countplot('State', data=df, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Investigate the different numbers of customers in each class. We can see that there are more customers who did not churn than those that did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAERCAYAAACXY7U1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmmsdva5zqXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x171a6d610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.plt.figure(figsize=(8,4))\n",
    "sns.countplot('Churn?', data=df, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the Data Frame\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we will deal with creating labels that can be worked with - 0s for customers that did not churn, and 1s for customers that did in fact churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for value in df[\"Churn?\"]:\n",
    "    if value == \"True.\":\n",
    "        labels.append(1)\n",
    "    else: \n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n",
      "2850\n",
      "5.90062111801\n"
     ]
    }
   ],
   "source": [
    "print labels.count(1)\n",
    "print labels.count(0)\n",
    "print (labels.count(0)*1.0)/labels.count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The above counts show us the exact ratio at which our classes are imbalanced - in this data set there are approximately six times as many customers that did not churn as those that did churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We can take a look at the newly modified dataframe to ensure that the 1s and 0s were added correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0    KS             128        415  382-4657         no        yes   \n",
       "1    OH             107        415  371-7191         no        yes   \n",
       "2    NJ             137        415  358-1921         no         no   \n",
       "3    OH              84        408  375-9999        yes         no   \n",
       "4    OK              75        415  330-6626        yes         no   \n",
       "\n",
       "   VMail Message  Day Mins  Day Calls  Day Charge   ...    Eve Charge  \\\n",
       "0             25     265.1        110       45.07   ...         16.78   \n",
       "1             26     161.6        123       27.47   ...         16.62   \n",
       "2              0     243.4        114       41.38   ...         10.30   \n",
       "3              0     299.4         71       50.90   ...          5.26   \n",
       "4              0     166.7        113       28.34   ...         12.61   \n",
       "\n",
       "   Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
       "0       244.7           91         11.01       10.0           3         2.70   \n",
       "1       254.4          103         11.45       13.7           3         3.70   \n",
       "2       162.6          104          7.32       12.2           5         3.29   \n",
       "3       196.9           89          8.86        6.6           7         1.78   \n",
       "4       186.9          121          8.41       10.1           3         2.73   \n",
       "\n",
       "   CustServ Calls  Churn?  labels  \n",
       "0               1  False.       0  \n",
       "1               1  False.       0  \n",
       "2               0  False.       0  \n",
       "3               2  False.       0  \n",
       "4               3  False.       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">As per good habits, here a copy of the data frame is created to work with going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0    KS             128        415  382-4657         no        yes   \n",
       "1    OH             107        415  371-7191         no        yes   \n",
       "2    NJ             137        415  358-1921         no         no   \n",
       "3    OH              84        408  375-9999        yes         no   \n",
       "4    OK              75        415  330-6626        yes         no   \n",
       "\n",
       "   VMail Message  Day Mins  Day Calls  Day Charge   ...    Eve Charge  \\\n",
       "0             25     265.1        110       45.07   ...         16.78   \n",
       "1             26     161.6        123       27.47   ...         16.62   \n",
       "2              0     243.4        114       41.38   ...         10.30   \n",
       "3              0     299.4         71       50.90   ...          5.26   \n",
       "4              0     166.7        113       28.34   ...         12.61   \n",
       "\n",
       "   Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
       "0       244.7           91         11.01       10.0           3         2.70   \n",
       "1       254.4          103         11.45       13.7           3         3.70   \n",
       "2       162.6          104          7.32       12.2           5         3.29   \n",
       "3       196.9           89          8.86        6.6           7         1.78   \n",
       "4       186.9          121          8.41       10.1           3         2.73   \n",
       "\n",
       "   CustServ Calls  Churn?  labels  \n",
       "0               1  False.       0  \n",
       "1               1  False.       0  \n",
       "2               0  False.       0  \n",
       "3               2  False.       0  \n",
       "4               3  False.       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start to clean up the data frame. The churn column is dropped because we replaced it with 0s and 1s, which we can use when developing a model. Area code is dropped because we can easily see that most of the entries are 415, rendering it largely ineffective. The phone number is dropped, because there will be no connection with a phone number's actual digits and whether there was a customer churn or not. Some may say that the customer's state does not matter. I can see both sides to this argument, but I prefer to err on the side of leaving it in as a feature for now. It seems like there is the potential for that information to be valuable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(\"Churn?\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(\"Area Code\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(\"Phone\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Inspecting our newly cleaned up data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length Int'l Plan VMail Plan  VMail Message  Day Mins  \\\n",
       "0    KS             128         no        yes             25     265.1   \n",
       "1    OH             107         no        yes             26     161.6   \n",
       "2    NJ             137         no         no              0     243.4   \n",
       "3    OH              84        yes         no              0     299.4   \n",
       "4    OK              75        yes         no              0     166.7   \n",
       "\n",
       "   Day Calls  Day Charge  Eve Mins  Eve Calls  Eve Charge  Night Mins  \\\n",
       "0        110       45.07     197.4         99       16.78       244.7   \n",
       "1        123       27.47     195.5        103       16.62       254.4   \n",
       "2        114       41.38     121.2        110       10.30       162.6   \n",
       "3         71       50.90      61.9         88        5.26       196.9   \n",
       "4        113       28.34     148.3        122       12.61       186.9   \n",
       "\n",
       "   Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
       "0           91         11.01       10.0           3         2.70   \n",
       "1          103         11.45       13.7           3         3.70   \n",
       "2          104          7.32       12.2           5         3.29   \n",
       "3           89          8.86        6.6           7         1.78   \n",
       "4          121          8.41       10.1           3         2.73   \n",
       "\n",
       "   CustServ Calls  labels  \n",
       "0               1       0  \n",
       "1               1       0  \n",
       "2               0       0  \n",
       "3               2       0  \n",
       "4               3       0  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The remaining columns that are not numbers (so state, international plan or not, and voicemail plan or not) now have to be converted to numbers so that they can properly be incorporated. Luckily, pandas includes a \"get dummies\" command to help us with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_cols = [\"State\", \"Int'l Plan\", \"VMail Plan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(df2, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Inspecting our newly modified data frame, that now has categorical features replaced with numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Length</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>...</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_VT</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WI</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "      <th>Int'l Plan_no</th>\n",
       "      <th>Int'l Plan_yes</th>\n",
       "      <th>VMail Plan_no</th>\n",
       "      <th>VMail Plan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Account Length  VMail Message  Day Mins  Day Calls  Day Charge  Eve Mins  \\\n",
       "0             128             25     265.1        110       45.07     197.4   \n",
       "1             107             26     161.6        123       27.47     195.5   \n",
       "2             137              0     243.4        114       41.38     121.2   \n",
       "3              84              0     299.4         71       50.90      61.9   \n",
       "4              75              0     166.7        113       28.34     148.3   \n",
       "\n",
       "   Eve Calls  Eve Charge  Night Mins  Night Calls       ...        State_VA  \\\n",
       "0         99       16.78       244.7           91       ...               0   \n",
       "1        103       16.62       254.4          103       ...               0   \n",
       "2        110       10.30       162.6          104       ...               0   \n",
       "3         88        5.26       196.9           89       ...               0   \n",
       "4        122       12.61       186.9          121       ...               0   \n",
       "\n",
       "   State_VT  State_WA  State_WI  State_WV  State_WY  Int'l Plan_no  \\\n",
       "0         0         0         0         0         0              1   \n",
       "1         0         0         0         0         0              1   \n",
       "2         0         0         0         0         0              1   \n",
       "3         0         0         0         0         0              0   \n",
       "4         0         0         0         0         0              0   \n",
       "\n",
       "   Int'l Plan_yes  VMail Plan_no  VMail Plan_yes  \n",
       "0               0              0               1  \n",
       "1               0              0               1  \n",
       "2               0              1               0  \n",
       "3               1              1               0  \n",
       "4               1              1               0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y to Us When Modeling:\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Now we need to actually create our X and y to start testing models out with. The below link was used for help with doing this while using a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df3.pop('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Looking at our X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Length</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>...</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_VT</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WI</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "      <th>Int'l Plan_no</th>\n",
       "      <th>Int'l Plan_yes</th>\n",
       "      <th>VMail Plan_no</th>\n",
       "      <th>VMail Plan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Account Length  VMail Message  Day Mins  Day Calls  Day Charge  Eve Mins  \\\n",
       "0             128             25     265.1        110       45.07     197.4   \n",
       "1             107             26     161.6        123       27.47     195.5   \n",
       "2             137              0     243.4        114       41.38     121.2   \n",
       "3              84              0     299.4         71       50.90      61.9   \n",
       "4              75              0     166.7        113       28.34     148.3   \n",
       "\n",
       "   Eve Calls  Eve Charge  Night Mins  Night Calls       ...        State_VA  \\\n",
       "0         99       16.78       244.7           91       ...               0   \n",
       "1        103       16.62       254.4          103       ...               0   \n",
       "2        110       10.30       162.6          104       ...               0   \n",
       "3         88        5.26       196.9           89       ...               0   \n",
       "4        122       12.61       186.9          121       ...               0   \n",
       "\n",
       "   State_VT  State_WA  State_WI  State_WV  State_WY  Int'l Plan_no  \\\n",
       "0         0         0         0         0         0              1   \n",
       "1         0         0         0         0         0              1   \n",
       "2         0         0         0         0         0              1   \n",
       "3         0         0         0         0         0              0   \n",
       "4         0         0         0         0         0              0   \n",
       "\n",
       "   Int'l Plan_yes  VMail Plan_no  VMail Plan_yes  \n",
       "0               0              0               1  \n",
       "1               0              0               1  \n",
       "2               0              1               0  \n",
       "3               1              1               0  \n",
       "4               1              1               0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Testing Models\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">A random forest is often considered one of the best ways to create a churn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score metric is one way of evaluating how a model performs. We can see that the random forest performs quite well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388489208633094"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, I am partial to sk-learn's built in classification report, which provides us with a far more granular look at a model's metrics. Accuracy does not actually give us that much information. The recall score on the '1' class is what I am most interested in. This tells us the percent of customers that were going to churn that our model actually caught. For a cell phone company, I believe this to be the most important thing that the model does, so this will be the metric of focus for me. Another metric the classification report gives us access to is a class' f1 score. This score is the harmonic mean of the class' precision and recall, and is often the preferred metric to use, since is based on two different sources of information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96       707\n",
      "          1       0.94      0.57      0.71       127\n",
      "\n",
      "avg / total       0.93      0.93      0.92       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,rfc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The gradient boosting classifier is a very strong classifier overall, so it is worth looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The model's accuracy is very impressive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94964028776978415"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Perhaps even more impressively, the model's recall and f1 score are both an improvement on the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97       707\n",
      "          1       0.89      0.70      0.78       127\n",
      "\n",
      "avg / total       0.94      0.94      0.94       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,gbc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">While random forest and gradient boosted classifiers may prove to be the best options, it would be remiss not to investigate other classifiers. Next up is logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The score is not as good as the first two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86091127098321341"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Even worse, the model's performance on customers who actually churned (the '1s') is very poor, amont all three metrics - precision, recall, and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92       718\n",
      "          1       0.50      0.19      0.27       116\n",
      "\n",
      "avg / total       0.83      0.86      0.83       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,lgr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Another model that could be used is the AdaBoost classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The accuracy seems decent, but as we saw with the logistic regression model, accuracy can hide problems with the smaller class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88369304556354911"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In a pleasant surprise, the AdaBoost classifier performs better than the logistic regression classifier for the class of customers that churned, but it was still not as good as the gradient boosted classifier or the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93       718\n",
      "          1       0.62      0.41      0.50       116\n",
      "\n",
      "avg / total       0.87      0.88      0.87       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,abc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Lastly is the SVM model. SVM models are well-known, are conceptually on the simpler side, and can be good if your data has imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The model seems ok according to accuracy, but remember, this can be very misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86091127098321341"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In fact, we can see that the model does terribly with customers that were classified as a 1! The error below occurs because the classification report was trying to divide by zero (that tells you how poorly the model was doing with the 1s class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93       718\n",
      "          1       0.00      0.00      0.00       116\n",
      "\n",
      "avg / total       0.74      0.86      0.80       834\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Based on the above metrics and the error, a reasonable hunch seems to be that the model simply predicted every single customer to NOT churn. This is easy to investigate, and as can be seen below, this is exactly what happened. The model predicted everyone to not churn, and since the not churn model was bigger, the accuracy did not seem terrible. Luckily, we were able to see through this via the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">After this whirlwind tour through various classifiers, it appears as if the first two we looked at, random forest and gradient boosted classifiers, performed the best. To see how much better they can become, we can now turn towards grid searching:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Models have parameters that can be tuned. A grid search can help us to find the ideal values to feed a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:   48.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'min_samples_split': 3, 'max_leaf_nodes': None, 'criterion': 'gini', 'max_depth': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rfc_grid = {'n_estimators': [5,10,20,100],\n",
    "                          'criterion': ['gini', 'entropy'],\n",
    "                          'max_depth': [10, 100, None],\n",
    "                          'max_leaf_nodes': [10, 100, None],\n",
    "                          'min_samples_split': [2,3,4]}\n",
    "\n",
    "rfc_gridsearch = GridSearchCV(RandomForestClassifier(),\n",
    "                             rfc_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='mean_squared_error')\n",
    "\n",
    "rfc_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print \"best parameters:\", rfc_gridsearch.best_params_\n",
    "\n",
    "best_model = rfc_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The above are the values that the grid search informs us will yield the best results. We then fit a new model that uses these parameters (max_depth and max_leaf_nodes merely stay at their defaults):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(n_estimators=100, criterion='gini', min_samples_split=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97       718\n",
      "          1       0.93      0.70      0.80       116\n",
      "\n",
      "avg / total       0.95      0.95      0.95       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,rfc2.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We can see that this new random forest, with the new parameters, outperforms the original random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc2_cross_val = cross_val_score(rfc2, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation of the rfc2 model:\n",
      "[ 0.93625498  0.94820717  0.936       0.944       0.916       0.956       0.94\n",
      "  0.93574297  0.93574297  0.95983936]\n",
      "\n",
      "\n",
      "Mean of these scores:\n",
      "0.94077874526\n"
     ]
    }
   ],
   "source": [
    "print \"Cross validation of the rfc2 model:\"\n",
    "print rfc2_cross_val\n",
    "print \"\\n\"\n",
    "print \"Mean of these scores:\"\n",
    "print rfc2_cross_val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This is just an exampe of cross validation with 10 folds. Bear in mind, though, that I am most interested in the model's performance on the class of customers who actually churned, so I do not put too much weight on this particular score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There may rightfully be some concern that the difference in sizes between the classes may cause some issues. Sci-Kit Learn includes a parameter that can automatically help with this. I thought it prudent to create a new model, using the same parameters as above, but with the 'class_weight' parameter set to automatically balance. Here is this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc3 = RandomForestClassifier(n_estimators=100, criterion='gini', min_samples_split=3, class_weight=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97       718\n",
      "          1       0.94      0.67      0.78       116\n",
      "\n",
      "avg / total       0.95      0.95      0.94       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,rfc3.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">At best, this model with class weights balanced seems comparable to the previous model, while at worst it may even be a hair worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc3_cross_val = cross_val_score(rfc3, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation of the rfc3 model:\n",
      "[ 0.94023904  0.94023904  0.932       0.936       0.92        0.936       0.932\n",
      "  0.93172691  0.91566265  0.92369478]\n",
      "\n",
      "\n",
      "Mean of these scores:\n",
      "0.9307562425\n"
     ]
    }
   ],
   "source": [
    "print \"Cross validation of the rfc3 model:\"\n",
    "print rfc3_cross_val\n",
    "print \"\\n\"\n",
    "print \"Mean of these scores:\"\n",
    "print rfc3_cross_val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In addition to what can be seen in the above metrics, the cross validation scores are also a little lower for the model that included the automatic weight balancing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Classifier Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'n_estimators': 100, 'loss': 'exponential', 'learning_rate': 0.2, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "gbc_grid = {'loss': ['deviance', 'exponential'],\n",
    "                          'learning_rate': [.01, .1, .2],\n",
    "                          'n_estimators': [50, 100, 250],\n",
    "                          'max_depth': [2, 3, 4]}\n",
    "\n",
    "gbc_gridsearch = GridSearchCV(GradientBoostingClassifier(),\n",
    "                             gbc_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='mean_squared_error')\n",
    "\n",
    "gbc_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print \"best parameters:\", gbc_gridsearch.best_params_\n",
    "\n",
    "best_model = gbc_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">These are the parameters that the grid search says will make the gradient boosted classifier perform the best. We then use these parameters to fit a new gradient boosted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc2 = GradientBoostingClassifier(n_estimators=100, loss='exponential', learning_rate=.2, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.2, loss='exponential',\n",
       "              max_depth=4, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       718\n",
      "          1       0.92      0.78      0.85       116\n",
      "\n",
      "avg / total       0.96      0.96      0.96       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test,gbc2.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We can see that this model outperforms the original gradient boosted model. It performs extremely well in fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc2_cross_val = cross_val_score(gbc2, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation of the gbc2 model:\n",
      "[ 0.93625498  0.9561753   0.952       0.968       0.928       0.972       0.96\n",
      "  0.96787149  0.97188755  0.96787149]\n",
      "\n",
      "\n",
      "Mean of these scores:\n",
      "0.958006080097\n"
     ]
    }
   ],
   "source": [
    "print \"Cross validation of the gbc2 model:\"\n",
    "print gbc2_cross_val\n",
    "print \"\\n\"\n",
    "print \"Mean of these scores:\"\n",
    "print gbc2_cross_val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Ultimately, both the tuned random forest and gradient boosted classifiers performed quite well. I think that for a business, correctly identifying potential customers that may soon churn is the most important thing the model can do. As such, that's why I made my focus the recall score on the customers who actually churned. The gradient boosted classifier correctly identified approximately 78% of the customers who churned in the test set. This was better than the random forest classifier. However, this came at the cost of the churn class' precision, which was only at 92%, as compared to 94% for the random forest model. This means that the gradient boosted model may be slightly more prone to classify customers as likely to churn when in fact they won't. However, these numbers are only for the model's performance on a test set, and in the real world, things may be different. The differences may actually prove negligible. \n",
    "\n",
    ">I don't consider small dip in churn class precision as overly harmful to the company - if they go out of their way to appease customers in order to get them stay, and are wrong on 8% of these customers, that shouldn't lead to much lasting harm. On the other hand, misidentifying customers who are going to churn as not likely to churn puts the company at risk of losing that customer. For this reason, the gradient boosted class' 78% success rate at identifying these customers is very attractive. \n",
    "\n",
    ">Between the final two models above, I'm not really sure if it could be said that one is 'better.' Obviously, the gradient boosted classifier has slightly better metrics (for example its churn class f1 score is noticeably higher), but it is also computationally more expensive (if time to run on my computer is any indication). It also would be harder to explain what gradient boosting is to an audience. That is not to say that a random forest would be easy to explain, but it would probably be easier.\n",
    "\n",
    ">Overall, I think both of the final two models above performed quite well. If I absolutely had to pick one model, I would go with the gradient boosted classifier, just because it's churn customer recall was so impressive. I think this is the most important performance metric for a business, and it did well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The goal of a model is always to provide business insights. This section briefly looks at other information the models can give to us that may be of use to the company. The models can tell us what features were the most important:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_importances = rfc2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03162274,  0.01542208,  0.14005463,  0.03377061,  0.12574378,\n",
       "        0.05546933,  0.02738979,  0.0532123 ,  0.03469096,  0.02859275,\n",
       "        0.03515965,  0.04250411,  0.0426047 ,  0.04309493,  0.10052261,\n",
       "        0.00108321,  0.00076396,  0.00147525,  0.00118324,  0.00191014,\n",
       "        0.00208436,  0.00333985,  0.00135229,  0.00158283,  0.0007644 ,\n",
       "        0.0011197 ,  0.00047233,  0.00060153,  0.00175519,  0.00091735,\n",
       "        0.00169755,  0.0017431 ,  0.00052889,  0.00201593,  0.00235326,\n",
       "        0.00247075,  0.00341126,  0.00140007,  0.00235633,  0.00066788,\n",
       "        0.00465273,  0.00235174,  0.00131376,  0.0012259 ,  0.00161093,\n",
       "        0.00141816,  0.00335859,  0.00075357,  0.00164996,  0.00128916,\n",
       "        0.00243981,  0.00096923,  0.00251832,  0.00138486,  0.00114718,\n",
       "        0.0038736 ,  0.00066999,  0.00087789,  0.00314398,  0.00136038,\n",
       "        0.00154102,  0.00159828,  0.00237751,  0.00118834,  0.00106365,\n",
       "        0.0008122 ,  0.03802323,  0.04126389,  0.01267602,  0.01254047])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_importances = gbc2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07758173,  0.02570511,  0.07107894,  0.08721612,  0.07603046,\n",
       "        0.05224682,  0.04347791,  0.05623337,  0.07108051,  0.06645883,\n",
       "        0.03721205,  0.0405576 ,  0.04673469,  0.03802773,  0.04694827,\n",
       "        0.        ,  0.00188919,  0.        ,  0.0007823 ,  0.00064006,\n",
       "        0.00948357,  0.00636992,  0.01630551,  0.00015115,  0.        ,\n",
       "        0.01046619,  0.00111777,  0.00050981,  0.0027025 ,  0.00148102,\n",
       "        0.0013214 ,  0.00348073,  0.        ,  0.00328886,  0.00405178,\n",
       "        0.00172099,  0.0081328 ,  0.00097859,  0.00036405,  0.00042437,\n",
       "        0.00438255,  0.00423897,  0.00084865,  0.00133264,  0.00356641,\n",
       "        0.00370893,  0.00252907,  0.        ,  0.0002845 ,  0.00028915,\n",
       "        0.00244712,  0.        ,  0.00073757,  0.0039116 ,  0.00203557,\n",
       "        0.00349453,  0.00128704,  0.        ,  0.00328671,  0.00353572,\n",
       "        0.01514204,  0.        ,  0.00188924,  0.        ,  0.00029779,\n",
       "        0.00134091,  0.00582297,  0.00758856,  0.00515639,  0.0085927 ])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(df3.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Features According to Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_pairs = zip(features, rf_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top ten features according to the random forest model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Day Mins', 0.14005463460451739),\n",
       " ('Day Charge', 0.12574377595145381),\n",
       " ('CustServ Calls', 0.10052260582185404),\n",
       " ('Eve Mins', 0.055469328066938585),\n",
       " ('Eve Charge', 0.053212302125255795),\n",
       " ('Intl Charge', 0.043094933497838189),\n",
       " ('Intl Calls', 0.042604695334240231),\n",
       " ('Intl Mins', 0.042504107808711319),\n",
       " (\"Int'l Plan_yes\", 0.041263891178773111),\n",
       " (\"Int'l Plan_no\", 0.038023231980670445)]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://stackoverflow.com/questions/10695139/sort-a-list-of-tuples-by-2nd-item-integer-value\n",
    "print \"The top ten features according to the random forest model:\"\n",
    "sorted(rf_pairs, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_pairs = zip(features, gb_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top ten features according to the gradient boosted classifier model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Day Calls', 0.08721611526076338),\n",
       " ('Account Length', 0.077581730155666523),\n",
       " ('Day Charge', 0.076030458759742695),\n",
       " ('Night Mins', 0.071080514260919381),\n",
       " ('Day Mins', 0.071078941345548957),\n",
       " ('Night Calls', 0.066458832252557137),\n",
       " ('Eve Charge', 0.056233370964154761),\n",
       " ('Eve Mins', 0.052246816895930255),\n",
       " ('CustServ Calls', 0.046948265316233556),\n",
       " ('Intl Calls', 0.046734687468998518)]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"The top ten features according to the gradient boosted classifier model:\"\n",
    "sorted(gb_pairs, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Day Charge appears in the top three importances for both models. Let's investigate by looking at the average day charge for customers who churned, and for those who didn't churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day_charge = df3['Day Charge'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(45.07, 0),\n",
       " (27.469999999999999, 0),\n",
       " (41.380000000000003, 0),\n",
       " (50.899999999999999, 0),\n",
       " (28.34, 0)]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = zip(day_charge, labels)\n",
    "dc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n",
      "2850\n"
     ]
    }
   ],
   "source": [
    "print labels.count(1)\n",
    "print labels.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average day charge for a customer who churned:  35.1759213251\n",
      "Average day charge fo ra customer who did not churn:  29.7804210526\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for pair in dc:\n",
    "    if pair[1]==1:\n",
    "        sum += pair[0]\n",
    "print \"Average day charge for a customer who churned: \", sum/483.\n",
    "\n",
    "sum = 0\n",
    "for pair in dc:\n",
    "    if pair[1]==0:\n",
    "        sum += pair[0]\n",
    "print \"Average day charge fo ra customer who did not churn: \", sum/2850."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Interesting. The average day charge for customers who churned is noticeably higher than the average day charge for customers who did not churn. Let's continue the analysis. The day minutes feature was in the top five for importance among both models as well. Let's look at the difference between the two classes' day minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_mins = df3['Day Mins'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(265.10000000000002, 0),\n",
       " (161.59999999999999, 0),\n",
       " (243.40000000000001, 0),\n",
       " (299.39999999999998, 0),\n",
       " (166.69999999999999, 0)]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = zip(day_mins, labels)\n",
    "dm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average day minutes for customers who churned:  206.914078675\n",
      "The average day minutes for customers who did not churn:  175.175754386\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for pair in dm:\n",
    "    if pair[1]==1:\n",
    "        sum += pair[0]\n",
    "print \"The average day minutes for customers who churned: \", sum/483.\n",
    "\n",
    "sum = 0\n",
    "for pair in dm:\n",
    "    if pair[1]==0:\n",
    "        sum += pair[0]\n",
    "print \"The average day minutes for customers who did not churn: \", sum/2850."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Also very interesting. The day minutes usage was also noticeably higher for customers who churned than those who did not churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to Take This"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Judging by these two features, it appears that customers who simply use the service more (having higher day charges or higher day minutes, for example) are more likely to churn. Now, this is in no way definitive - it is just one avenue that could be explored. This was a very basic, surface-level look at the issue, and it is likely more complicated than that. However, it could be a place to start. Perhaps the people who use the service more are business users, who will switch companies at the slightest bit of downtime in their service. Perhaps these users who use the service the most and pay a lot of money to do so simply get frustrated when they have issues, and think they should be treated better, so they leave their current cell service provider. To counteract this, maybe the company could start offering 'thank yous' or rewards to customers who spend the most or use the most minutes. This could potentially appease that group of customers, who look like they may be prone to churn. If they can make those customers happy, maybe they will not churn as much. Again, it must be cautioned that this is not definitive, but it could be something that is worth looking further into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
